---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>



I am a Ph.D. candidate at Language Computing and Machine Learning Group ([LANCO](https://lancopku.github.io/)), Institute of Computational Linguistics (**State Key Laboratory for Multimedia Information Processing**) ([icl](http://icl.pku.edu.cn/)), [School of Computer Science](https://cs.pku.edu.cn/), [Peking University](https://www.pku.edu.cn/) without entrance examination, supervised by Prof. [Xu Sun](https://xusun.org/). Before that, I got a Bachelor's degree from [School of Computer Science and Technology](https://www.sdu.edu.cn/), [Shandong University](https://www.sdu.edu.cn/), with a solid foundation in mathematics, strong learning ability, excellent competition results and rich research experience, advised by Prof. [Xuemeng Song](https://xuemengsong.github.io/).

My research interests include NLP, LLM, quantitative finance and multimodal learning.

I am looking for research collaborations in the field of Multimodal NLP and Video Understanding, please feel free to contact me at [Email](kunouyang10@gmail.com) kunouyang10**AT**gmail**DOT**com.



# 🔥 News
- *2024.12* &nbsp;🎉🎉 One paper got accepted by IEEE TMM. 
- *2023.05* &nbsp;🎉🎉 One paper got accepted by ACL 2023 (main conference). 

# 📝 Preprints

  
[PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension](https://arxiv.org/pdf/2412.11906?)

**Kun Ouyang**, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun
  
# 📝 Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TEAM</div><img src='images/acl_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-source semantic graph-based multimodal sarcasm explanation generation](https://aclanthology.org/2023.acl-long.635.pdf) **ACL 2023**

Liqiang Jing, Xuemeng Song, **Kun Ouyang**, Mengzhao Jia, Liqiang Nie.

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EDGE</div><img src='images/tmm_01.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue](https://arxiv.org/pdf/2402.03658) **IEEE TMM**

**Kun Ouyang**, Liqiang Jing, Xuemeng Song, Meng Liu, Yupeng Hu, Liqiang Nie


</div>
</div>


# 🎖 Honors and Awards
 Merit Graduate Student, Shandong University.

# 📖 Educations
- *2024.09 - 2029.06 (expected)*, School of Computer Science, Peking University.
- *2020.09 - 2024.06*, Artificial Intelligence, School of Computer Science and Technology, Shandong University. 



