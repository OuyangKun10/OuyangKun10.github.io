---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>



I am a **first** year Ph.D. student at Language Computing and Machine Learning Group ([LANCO](https://lancopku.github.io/)), Institute of Computational Linguistics (**State Key Laboratory for Multimedia Information Processing**) ([icl](http://icl.pku.edu.cn/)), [School of Computer Science](https://cs.pku.edu.cn/), [Peking University](https://www.pku.edu.cn/) without entrance examination, supervised by Prof. [Xu Sun](https://xusun.org/). Before that, I got a B.E. degree from [School of Computer Science and Technology](https://www.sdu.edu.cn/), [Shandong University](https://www.sdu.edu.cn/), with a solid foundation in mathematics, strong learning ability, excellent competition results and rich research experience, advised by Prof. [Xuemeng Song](https://xuemengsong.github.io/).

My research interests include NLP, LLM, quantitative finance and multimodal learning.

I am looking for research collaborations in the field of Multimodal NLP and Video Understanding, please feel free to contact me at [Email](kunouyang10@gmail.com) kunouyang10**AT**gmail**DOT**com.



# üî• News
- *2025.05* &nbsp;üéâüéâ Two papers got accepted by ACL 2025. 
- *2024.12* &nbsp;üéâüéâ One paper got accepted by IEEE TMM. 
- *2023.05* &nbsp;üéâüéâ One paper got accepted by ACL 2023. 

# üìù Preprints


**VIDEOREASONBENCH: Can MLLMs Perform Vision-Centric Complex Video Reasoning?**

Yuanxin Liu, **Kun Ouyang**, Haoning Wu, Yi Liu, Lin Sui, Xinhao Li, Yan Zhong, Y. Charles, Xinyu Zhou, Xu Sun

[SpaceR: Reinforcing MLLMs in Video Spatial Reasoning](https://doi.org/10.48550/arXiv.2504.01805)

**Kun Ouyang**, Yuanxin Liu, Haoning Wu, Yi Liu, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun

**WONDER: Weight-Adaptive Optimization with Data Selection for Multimodal Reasoning**

Yi Liu, Shicheng Li, Yuanxin Liu, **Kun Ouyang**, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun

[TEMPO: Temporal Preference Optimization of Video LLMs via Difficulty Scheduling and Pre-SFT Alignment](https://arxiv.org/abs/2503.16929)

Shicheng Li, Lei Li, **Kun Ouyang**, Shuhuai Ren, Yuanxin Liu, Yuanxing Zhang, Fuzheng Zhang, Lingpeng Kong, Qi Liu, Xu Sun

[TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos](https://arxiv.org/abs/2504.17343)

Linli Yao, Yicheng Li, Yuancheng Wei, Lei Li, Shuhuai Ren, Yuanxin Liu, **Kun Ouyang**, Lean Wang, Shicheng Li, Sida Li, Lingpeng Kong, Qi Liu, Yuanxing Zhang, Xu Sun
  
# üìù Publications 


[PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension](https://arxiv.org/pdf/2412.11906?) **ACL 2025**

**Kun Ouyang**, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun


[Generative Frame Sampler for Long Video Understanding](https://arxiv.org/html/2503.09146v1) **ACL 2025** (findings)

Linli Yao, Haoning Wu, **Kun Ouyang**, Yuanxing Zhang, Caiming Xiong, Bei Chen, Xu Sun, Junnan Li


[Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue](https://arxiv.org/pdf/2402.03658) **IEEE TMM**

**Kun Ouyang**, Liqiang Jing, Xuemeng Song, Meng Liu, Yupeng Hu, Liqiang Nie

[Multi-source semantic graph-based multimodal sarcasm explanation generation](https://aclanthology.org/2023.acl-long.635.pdf) **ACL 2023**

Liqiang Jing, Xuemeng Song, **Kun Ouyang**, Mengzhao Jia, Liqiang Nie.


# üìñ Educations
- *2024.09 - 2029.06 (expected)*, School of Computer Science, Peking University.
- *2020.09 - 2024.06*, Artificial Intelligence, School of Computer Science and Technology, Shandong University. 

# üíª Internships

- *2024-2025*, Tencent AI lab.

- *2023.10 - 2024.02*, Mizuho Securities Co., Ltd.




